# -*- coding: utf-8 -*-
"""Proiect_IA.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I7hjh0HJqy7CNMI_7UYiYzliUPNOTOO6
"""

import pandas as pd
import numpy as np
from google.colab import files
#upload files in linie comanda
setdate = files.upload()
print(setdate)
#citirea datelor din fisierul csv
heart_set = pd.read_csv('heart_data.csv')
#afisare primele randuri din heart_set
heart_array=np.array(heart_set)
print("----SET DE DATE-----")
heart_set.head()
#heart_set.head(1)-afiseaza doar un rand

#afisare dimensiune matrice
heart_set.shape
print(heart_set.columns)

print("----ARRAY REST_BP-----")
#prima coloana pentru care facem val cea mai frecv, matricea, media, val medie este rest_bt=Resting blood pressure (mm Hg)
col_rest_bp_array=heart_array[:,0]
print(col_rest_bp_array)#afisare matrice
#media aritmetica
mean_col_rest_bp_array=np.mean(col_rest_bp_array, axis=0)
print("mean(media aritmetica)=",mean_col_rest_bp_array)
#valoarea medie
median_col_rest_bp_array=np.median(col_rest_bp_array, axis=0)
print("median(valoarea medie)=",median_col_rest_bp_array)
#valoarea maxima din coloana
maximum_col_rest_bp_array=np.max(col_rest_bp_array)
print("maximum=", maximum_col_rest_bp_array)

#gaseste frecventa fiecarei valori
values, counts = np.unique(col_rest_bp_array, return_counts=True)
#afiseaza valoarea cu cea mai mare frecventa
print("most_frequent_value=", values[counts.argmax()])

#indexul incepe de la 0, col rest_bt fiind prima vom avea index 0
#raw_rest_bp=heart_array[0,:]
#print(raw_rest_bp)

print("----ARRAY AGE-----")
#coloana a patra, indexul incepe de la 0, age=Age of the patient (years)
col_age_array=heart_array[:,3]
print(col_age_array)
mean_col_age_array=np.mean(col_age_array, axis=0)
print("mean=",mean_col_age_array)
median_col_age_array=np.median(col_age_array, axis=0)
print("median=",median_col_age_array)
maximum_col_age_array=np.max(col_age_array)
print("maximum=",maximum_col_age_array)

#gaseste frecventa fiecarei valori
values, counts = np.unique(col_age_array, return_counts=True)
#afiseaza valoarea cu cea mai mare frecventa
print("most_frequent_value=", values[counts.argmax()])

print("----ARRAY MAX_HR-----")
#coloana a sasea, indexul incepe de la 0
col_max_hr_array=heart_array[:,5]
print(col_max_hr_array)
mean_col_max_hr_array=np.mean(col_max_hr_array, axis=0)
print("mean=",mean_col_max_hr_array)
median_col_max_hr_array=np.median(col_max_hr_array, axis=0)
print("median=",median_col_max_hr_array)
maximum_col_max_hr_array=np.max(col_max_hr_array)
print("maximum=",maximum_col_max_hr_array)

#gaseste frecventa fiecarei valori
values, counts = np.unique(col_max_hr_array, return_counts=True)
#afiseaza valoarea cu cea mai mare frecventa
print("most_frequent_value=", values[counts.argmax()])

print("----ARRAY CHOLESTEROL-----")
#coloana a 10a, indexul incepe de la 0
col_cholesterol_array=heart_array[:,9]
print(col_cholesterol_array)
mean_col_cholesterol_array=np.mean(col_cholesterol_array, axis=0)
print("mean=",mean_col_cholesterol_array)
median_col_cholesterol_array=np.median(col_cholesterol_array, axis=0)
print("median=",median_col_cholesterol_array)
maximum_col_cholesterol_array=np.max(col_cholesterol_array)
print("maximum=",maximum_col_cholesterol_array)

#gaseste frecventa fiecarei valori
values, counts = np.unique(col_cholesterol_array, return_counts=True)
#afiseaza valoarea cu cea mai mare frecventa
print("most_frequent_value=", values[counts.argmax()])

print("----ARRAY ST_DEPRESSION-----")
#coloana a 11a, indexul incepe de la 0
col_st_depression_array=heart_array[:,10]
print(col_st_depression_array)
mean_col_st_depression_array=np.mean(col_st_depression_array, axis=0)
print("mean=",mean_col_st_depression_array)
median_col_st_depression_array=np.median(col_st_depression_array, axis=0)
print("median=",median_col_st_depression_array)
maximum_col_st_depression_array=np.max(col_st_depression_array)
print("maximum=",maximum_col_st_depression_array)

#gaseste frecventa fiecarei valori
values, counts = np.unique(col_st_depression_array, return_counts=True)
#afiseaza valoarea cu cea mai mare frecventa
print("most_frequent_value=",values[counts.argmax()])

# Coloanele din array-ul heart_array alese mai sus
selected_columns = [0, 1, 5, 9, 10]

# Calcularea și afișarea gama și deviația standard pentru fiecare coloană selectată
for column_index in selected_columns:
    column_data = heart_array[:, column_index].astype(float)  # Convertim valorile în float pentru a evita erorile
    column_range = np.ptp(column_data) #calculează intervalul (diferența dintre maxim și minim) al valorilor din column_data
    column_std = np.std(column_data) #calculează deviația standard a valorilor din column_data
    print(f"Coloana {column_index}: Range = {column_range}, Deviația standard = {column_std}")

import matplotlib.pyplot as plt

# Coloanele din array-ul heart_array pentru care dorim să afisam graficele
selected_columns = [0, 1, 5, 9, 10] #["rest_bp", "chest_pain", "max_hr", "cholesterol", "st_depression"]

# Setul de date
for column_index in selected_columns:
    column_data = heart_array[:, column_index].astype(float)  # Convertim valorile în float pentru a evita erorile

    # Histograma
    plt.figure(figsize=(8, 6))
    plt.hist(column_data, bins=10, color='skyblue', edgecolor='black')
    plt.title(f'Histograma pentru coloana {column_index}')
    plt.xlabel('Valori')
    plt.ylabel('Frecvență')
    plt.show()

    # Graficul cu cutii (box plot)
    plt.figure(figsize=(8, 6))
    plt.boxplot(column_data)
    plt.title(f'Graficul cu cutii pentru coloana {column_index}')
    plt.ylabel('Valori')
    plt.show()

import matplotlib.pyplot as plt

# Coloanele din DataFrame-ul heart_set pentru care dorim să afișăm graficele
selected_columns = ["rest_bp", "chest_pain", "max_hr", "cholesterol", "st_depression"]

# Setul de date
for column_name in selected_columns:
    plt.figure(figsize=(8, 6))
    plt.scatter(heart_set.index, heart_set[column_name], color='green')
    plt.title(f'Scatter Plot of {column_name} vs Index')
    plt.xlabel('Index')
    plt.ylabel(column_name)
    plt.show()

import matplotlib.pyplot as plt
#scatter plot
plt.scatter(heart_set["rest_bp"], heart_set["age"])
plt.xlabel("Resting Blood Pressure")
plt.ylabel("Age")
plt.title("Scatter Plot of Resting Blood Pressure vs Age")
plt.show()

import matplotlib.pyplot as plt
#scatter plot
plt.scatter(heart_set["st_depression"], heart_set["diagnosis"])
plt.xlabel("St. depression")
plt.ylabel("Diagnosis")
plt.title("Scatter Plot of St. depression vs Diagnosis")
plt.show()

# Selectam cel putin 5 coloane, inclusiv coloana țintă (diagnosis)
selected_columns = ['rest_bp', 'age', 'max_hr', 'cholesterol', 'st_depression', 'diagnosis']

# Calcularea matricei de corelatii
correlation_matrix = heart_set[selected_columns].corr()

# Afisarea matricei de corelatii
print("Matricea de corelatii:")
print(correlation_matrix)

# Afisarea corelatiilor cu coloana tinta (diagnosis)
target_correlations = correlation_matrix['diagnosis'].drop('diagnosis')  # Eliminam corelatia cu ea insasi
print("\nCorelatiile cu coloana tinta (diagnosis):")
print(target_correlations)

import pandas as pd
import numpy as np
from google.colab import files
#upload files in linie comanda
setdate = files.upload()
print(setdate)
#citirea datelor din fisierul csv
heart_set = pd.read_csv('heart_data.csv')
#afisare primele randuri din heart_set
heart_array=np.array(heart_set)
print("----SET DE DATE-----")
heart_set.head()
#heart_set.head(1)-afiseaza doar un rand

print("Coloana de iesire-predictia:")
print(heart_set['diagnosis'])

heart_set.shape

x=heart_set.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, 10]].values
y=heart_set.iloc[:,13].values
print("coloane de intrare",x)
print("coloana de iesire",y)

print("set de antrenare")
x.shape

print("set de testare")
y.shape

# impartirea setului de date:
# X_train = intrari set de antrenare
# X_test = iesire set de antrenare
# y_train - intrari set de testare
# y_test - iesiri set de testare
# test_size=0.2: 20% setul de testare; 80% setul de antrenare

from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
from google.colab import files
#upload files in linie comanda
setdate = files.upload()
print(setdate)
#citirea datelor din fisierul csv
heart_set = pd.read_csv('heart_data.csv')
x=heart_set.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, 10]].values
y=heart_set.iloc[:,13].values
x_train,x_test, y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0, stratify=y)
print("X_train:")
print(x_train.shape)

print("X_test:")
print(x_test.shape)

print("y_train:")
print(y_train.shape)

print("y_test:")
print(y_test.shape)

import pandas as pd
import matplotlib.pyplot as plt

# Crearea setului de date
df = pd.DataFrame(heart_set.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 10, 13]])  # Selectia coloanelor de la 0 la 7,10 pentru antrenare si coloana 13 pentru test

# Vizualizarea datelor
display(df)

df.plot(title='Plot inainte de normalizari',kind='bar')

# Normalizarea min-max
df_normalizat = df.copy()
for column in df_normalizat.columns[:-1]:  # Excludem ultima coloana care este pentru testare
    df_normalizat[column] = (df_normalizat[column] - df_normalizat[column].min()) / (df_normalizat[column].max() - df_normalizat[column].min())

display('Normalizare min-max', df_normalizat)
df_normalizat.plot(title='Normalizare min-max',kind='bar')

# Normalizarea maxim absolut
df_max = df.copy()
for column in df_max.columns[:-1]:  # Excludem ultima coloana care este pentru testare
    df_max[column] = df_max[column] / df_max[column].abs().max()

display('Normalizare maxim absolut', df_max)
df_max.plot(title='Normalizare maxim absolut',kind='bar')

# Normalizarea score-z (standardizare)
df_standardizat = df.copy()

for column in df_standardizat.columns[:-1]:  # Excludem ultima coloana care este pentru testare
    df_standardizat[column] = (df_standardizat[column] -
                               df_standardizat[column].mean()) / df_standardizat[column].std()

display('Standardizare', df_standardizat)
df_standardizat.plot(title='Standardizare',kind='bar')

#crearea modelului retelei neuronale- NR. 2
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD,Adam
import tensorflow as tf

model = Sequential()

# stratul de intrare:
# 1) numarul de neuroni =
# 2) functia de activare =
# 3) intrari = 9
# Adăugarea stratului de intrare
model.add(Dense(units=12, activation='relu', input_dim=9))

#strat ascuns
model.add(tf.keras.layers.Dense(units=8, activation='relu'))

#strat de iesire
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

# compilarea modelului cu functia de optimizare Adam; lr - rata de invatare; metrics = accuracy (acuratetea pentru cazul de iesiri binare)
model.compile(Adam(lr=0.04), 'binary_crossentropy', metrics=['accuracy'])

# afisarea modelului
model.summary()

# Antrenarea modelului neuronal
model.fit(x_train,y_train,epochs=100)

# predictia modelului neuronal - metoda 1
y_pred = model.predict(x_test)

print(y_pred)

y_test_class = y_test
y_pred_class = np.argmax(y_pred,axis=1)

from sklearn.metrics import classification_report,confusion_matrix
# raportului de estimare - acuratetea valorilor estimate
print(classification_report(y_test_class,y_pred_class))

# predictia modelului neuronal - metoda 2
y_test_class = y_test
out_pred=np.argmax(model.predict(x_test), axis=-1)

print(out_pred)

out_pred[0], y_test_class[0]

# Calculul acurateței pe setul de antrenare
train_loss, train_accuracy = model.evaluate(x_train, y_train)
print("Acuratețea la antrenare:", train_accuracy)

# Calculul acurateței pe setul de testare
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Acuratețea la testare:", test_accuracy)

#crearea modelului retelei neuronale- NR. 5
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD,Adam
import tensorflow as tf

model = Sequential()

# stratul de intrare:
# 1) numarul de neuroni =
# 2) functia de activare =
# 3) intrari = 9
# Adăugarea stratului de intrare
model.add(Dense(units=16, activation='relu', input_dim=9))

#strat ascuns
model.add(tf.keras.layers.Dense(units=14, activation='relu'))

#strat de iesire
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

# compilarea modelului cu functia de optimizare Adam; lr - rata de invatare; metrics = accuracy (acuratetea pentru cazul de iesiri binare)
model.compile(Adam(lr=0.04), 'binary_crossentropy', metrics=['accuracy'])

# afisarea modelului
model.summary()

# Antrenarea modelului neuronal
model.fit(x_train,y_train,epochs=100)

# Calculul acurateței pe setul de antrenare
train_loss, train_accuracy = model.evaluate(x_train, y_train)
print("Acuratețea la antrenare:", train_accuracy)

# Calculul acurateței pe setul de testare
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Acuratețea la testare:", test_accuracy)

# Generarea graficului pentru acuratețe
plt.figure(figsize=(12, 4))

# Acuratețea
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='best')

# Pierderea
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='best')

plt.show()

import pandas as pd

df = pd.read_csv('heart_data.csv')

# Afisam numarului de valori 1 si 0 în coloana diagnosis
counts = df['diagnosis'].value_counts()
print(counts)

# Putem accesa separat numarul de valori 0 și 1
num_zeros = counts[0]
num_ones = counts[1]

print(f"Numarul de valori 0: {num_zeros}")
print(f"Numarul de valori 1: {num_ones}")

#crearea modelului retelei neuronale-NR. 1
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD,Adam
import tensorflow as tf

model = Sequential()

# stratul de intrare:
# 1) numarul de neuroni =
# 2) functia de activare = tanh
# 3) intrari = 8
# Adăugarea stratului de intrare
model.add(Dense(units=12, activation='relu', input_dim=5))

#strat ascuns
model.add(tf.keras.layers.Dense(units=8, activation='relu'))

#strat de iesire
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

# compilarea modelului cu functia de optimizare Adam; lr - rata de invatare; metrics = accuracy (acuratetea pentru cazul de iesiri binare)
model.compile(Adam(lr=0.04), 'binary_crossentropy', metrics=['accuracy'])

# afisarea modelului
model.summary()

#crearea modelului retelei neuronale- NR. 3
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD,Adam
import tensorflow as tf

model = Sequential()

# stratul de intrare:
# 1) numarul de neuroni =
# 2) functia de activare = tanh
# 3) intrari = 8
# Adăugarea stratului de intrare
model.add(Dense(units=20, activation='relu', input_dim=9))

#strat ascuns
model.add(tf.keras.layers.Dense(units=12, activation='relu'))

#strat de iesire
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

# compilarea modelului cu functia de optimizare Adam; lr - rata de invatare; metrics = accuracy (acuratetea pentru cazul de iesiri binare)
model.compile(Adam(lr=0.04), 'binary_crossentropy', metrics=['accuracy'])

# afisarea modelului
model.summary()

#crearea modelului retelei neuronale-NR. 4
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD,Adam
import tensorflow as tf

model = Sequential()

# stratul de intrare:
# 1) numarul de neuroni =
# 2) functia de activare = tanh
# 3) intrari = 8
# Adăugarea stratului de intrare
model.add(Dense(units=16, activation='relu', input_dim=9))

#strat ascuns
model.add(tf.keras.layers.Dense(units=12, activation='relu'))

#strat de iesire
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

# compilarea modelului cu functia de optimizare Adam; lr - rata de invatare; metrics = accuracy (acuratetea pentru cazul de iesiri binare)
model.compile(Adam(lr=0.04), 'binary_crossentropy', metrics=['accuracy'])

# afisarea modelului
model.summary()

from google.colab import drive
drive.mount('/content/drive')

"""# Secțiune nouă"""